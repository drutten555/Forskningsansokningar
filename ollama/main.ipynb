{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Load packages and env, set up client, paths etc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import fitz # PyMuPDF\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import ast\n",
    "\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "## Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "## Set up client\n",
    "MODEL = \"llama3.1\"\n",
    "client = OpenAI(\n",
    "    base_url = \"http://localhost:11434/v1\",\n",
    "    api_key=\"ollama\", # required, but unused\n",
    ")\n",
    "\n",
    "## Folder paths set here\n",
    "outFolder = os.getenv(\"OUT_DIR_PATH\")\n",
    "testFolder = os.getenv(\"TEST_DIR_PATH\")\n",
    "\n",
    "pdfAvslagFolder = os.getenv(\"PDF_AVSLAG_PATH\")\n",
    "txtAvslagFolder = os.getenv(\"TXT_AVSLAG_PATH\")\n",
    "\n",
    "pdfBeviljadeFolder = os.getenv(\"PDF_BEV_PATH\")\n",
    "txtBeviljadeFolder = os.getenv(\"TXT_BEV_PATH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadOnePDF(filePath: str) -> Document:\n",
    "    \"\"\"Take filepath, loads all pages of pdf to one document\n",
    "\n",
    "    Args:\n",
    "        filePath (str): Path to pdf-file\n",
    "\n",
    "    Returns:\n",
    "        Document: Document with text content of all pdf pages\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    with fitz.open(filePath) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return Document(page_content=text, metadata={\"source\": filePath})\n",
    "\n",
    "def loadPDFs(folderPath: str) -> List[Document]:\n",
    "    \"\"\"Take folderpath, load all pdfs to separate documents.\n",
    "\n",
    "    Args:\n",
    "        folderPath (str): Path to folder.\n",
    "\n",
    "    Returns:\n",
    "        List[Document]: List of documents with text content of all pdf-files.\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    for filename in os.listdir(folderPath):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            filePath = os.path.join(folderPath, filename)\n",
    "            docs.append(loadOnePDF(filePath))\n",
    "    return docs\n",
    "\n",
    "def PDFtoTXT(pdfFolder: str, txtFolder: str, verbose: bool = False) -> None:\n",
    "    \"\"\"Take folder of pdf's, fill an empty folder with .txt's - one for each pdf with it's content.\n",
    "\n",
    "    Args:\n",
    "        pdfFolder (str): Path to a folder of pdfs.\n",
    "        txtFolder (str): Path to output folder of .txt files.\n",
    "        verbose (bool, optional): _description_. Defaults to False.\n",
    "    \"\"\"\n",
    "    os.makedirs(txtFolder, exist_ok=True)   # Ensure the folder with txt-files exists\n",
    "    documents = loadPDFs(pdfFolder)\n",
    "    for document in documents:\n",
    "        # Extract the filename without extension and append .txt\n",
    "        pdfFilename = os.path.basename(document.metadata['source'])\n",
    "        txtFilename = os.path.splitext(pdfFilename)[0] + '.txt'\n",
    "        txtPath = os.path.join(txtFolder, txtFilename)\n",
    "\n",
    "        # Write document content to a text file\n",
    "        with open(txtPath, 'w') as file:\n",
    "            file.write(document.page_content)\n",
    "        if verbose:\n",
    "            print(f\"Converted {pdfFilename} to {txtFilename}\")\n",
    "\n",
    "def cleanJSONresponse(jsonResponse: str) -> json:\n",
    "    \"\"\"Turns an openai API-response to a usable json\n",
    "\n",
    "    Args:\n",
    "        jsonResponse (str): Content part of Response from openAI API client.\n",
    "\n",
    "    Returns:\n",
    "        json: Content included between '{' and '}'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Attempt to find the first and last curly brace to extract valid JSON\n",
    "    jsonResponse = jsonResponse.replace(\"\\n\", \"\")\n",
    "    try:\n",
    "        start = jsonResponse.index('{')\n",
    "        end = jsonResponse.rindex('}') + 1\n",
    "        json_str = jsonResponse[start:end]\n",
    "        return json.loads(json_str)\n",
    "    except (ValueError, json.JSONDecodeError) as e:\n",
    "        print(\"=> Failed to clean and parse JSON:\")\n",
    "        print(jsonResponse)\n",
    "        print(\"\\n\")\n",
    "        return None\n",
    "\n",
    "def write2json(file_name: str, json_txt: json) -> None:\n",
    "    \"\"\"Write content to JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_name (str): JSON file name.\n",
    "        json_txt (json): JSON object/content.\n",
    "    \"\"\"\n",
    "    outFolder = os.getenv('OUT_DIR_PATH')\n",
    "    jsonName = os.path.join(outFolder, file_name +'.json')\n",
    "    open(jsonName, 'w').close() # clear file\n",
    "    with open(jsonName, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(json_txt, json_file, indent=4, ensure_ascii=False)\n",
    " \n",
    "def txtFolder2json(txtFolder: str, task_fn: str, **kwargs) -> None:\n",
    "    \"\"\"Creates .json-file called the same as txtFolder: `txtFolder_task.json`.\n",
    "\n",
    "    Args:\n",
    "        txtFolder (str): Filepath to folder with .txt files.\n",
    "        task (str): Available tasks: \"grades\", \"comments\".\n",
    "    \"\"\"\n",
    "\n",
    "    # Read content from each .txt file and extract categories and grades.\n",
    "    extractedData = {}\n",
    "    for filename in tqdm(os.listdir(txtFolder)):\n",
    "        if filename.endswith('.txt'):\n",
    "            # Read txt file\n",
    "            with open(os.path.join(txtFolder, filename), 'r') as file:\n",
    "                fileContent = file.read()\n",
    "\n",
    "            # Get JSON with grades response from LLM.\n",
    "            task, results = task_fn(fileContent, **kwargs)\n",
    "\n",
    "            # Clean response to only contain JSON object. \n",
    "            jsonCleaned = cleanJSONresponse(results)\n",
    "            if jsonCleaned is not None:\n",
    "                extractedData[filename] = jsonCleaned\n",
    "    \n",
    "    folderName = os.path.basename(os.path.normpath(txtFolder))\n",
    "    write2json(f\"{folderName}_{task}\", extractedData)\n",
    "    print(f\"Nr. of successfully processed files to {folderName}_{task}.json: {len(extractedData)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Generate .txt from PDF folders**\n",
    "\n",
    "Process the pdfs to txt. Set \"verbose = True\" to print name of each document processed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDFtoTXT(pdfAvslagFolder, txtAvslagFolder, verbose = False) ## Avslag\n",
    "PDFtoTXT(pdfBeviljadeFolder, txtBeviljadeFolder, verbose = False) ## Beviljade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Extract Grades**\n",
    "\n",
    "**Generate and save.json from txtFolder**\n",
    "\n",
    "This cell might take a minute or three to run depending on how many documents are in the folders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractGrades(fileContent: str, categories: str) -> str:\n",
    "    \"\"\"Essentially asks openai API to extract the categories and grades from a document.\n",
    "\n",
    "    Args:\n",
    "        fileContent (str): The content of a .txt file (a string, that is).\n",
    "        categories (str): Assessment criterias.\n",
    "    \n",
    "    Returns:\n",
    "        task (str): Task name.\n",
    "        str: The content part of a response from LLM model.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": f\"\"\"You are a script that outputs that only outputs valid JSON format where assessment criterias are keys and grades are int values.\n",
    "                The output must be in valid JSON. Don't add explanation beyond the JSON. Don't make suggestions.\n",
    "                Your task is to extract the assessment criteria and the corresponding grade from the text.\n",
    "                The assessment criterias are: {categories}\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": f\"\"\"Extract assessment criterias and grades from the following text and \n",
    "                provide them in JSON format where assessment criterias are keys and grades are int values.\n",
    "                {fileContent}\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(model=MODEL, messages=messages, temperature=0.1)\n",
    "    return \"grades\", response.choices[0].message.content.strip()\n",
    "\n",
    "## Specify the client data categories here\n",
    "categories_Formas = \"\"\"\n",
    "    - Vetenskaplig frågeställning\n",
    "    - Metod och genomförande\n",
    "    - Vetenskaplig kompetens\n",
    "    - Frågeställningens samhällsnytta\n",
    "    - Slutbedömning\n",
    "\"\"\"\n",
    "\n",
    "categories_VR = \"\"\"\n",
    "    - Scientific quality of the proposed research\n",
    "    - Novelty and originality\n",
    "    - Merits of the applicant \n",
    "    - Feasibility\n",
    "    - Overall assessment of the application's scientific quality\n",
    "\"\"\"\n",
    "\n",
    "## Get the respective assessment criteria names.\n",
    "categories = categories_Formas if os.getenv(\"CLIENT_NAME\") == \"Formas\" else categories_VR\n",
    "\n",
    "txtFolder2json(txtBeviljadeFolder, task_fn=extractGrades, categories=categories)\n",
    "txtFolder2json(txtAvslagFolder, task_fn=extractGrades, categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Extract Comments**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract postive/negative comments into JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getComments(fileContent: str) -> str:\n",
    "    \"\"\"Asks LLM model to return a json with comments.\n",
    "\n",
    "    Args:\n",
    "        fileContent (str): The content of a .txt file (a string, that is).\n",
    "    \n",
    "    Returns:\n",
    "        task (str): Task name.\n",
    "        str: The content part of a response from LLM model.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a script that only outputs valid JSON format with the keys: 'positive', 'negative' and the value as list of concise comments.\n",
    "                The output must be in valid JSON. Don't add explanation beyond the JSON. Don't make suggestions.\n",
    "                Your task is to summarize the detailed written comments from research proposal reviews.\n",
    "                Ignore the grades and the other information.\n",
    "                If there are no detailed written comments due to recieving the lowest grade, only output 'Low score' as value as negative comment, don't make something up.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"\"\"Summarize the positive/negative detailed written comments from the following text: {BODY}. Ignore everything else.\n",
    "                Output must be in valid JSON with the keys: 'positive', 'negative' and the value as list of concise comments.\n",
    "                Output must include only valid JSON.\n",
    "            \"\"\".format(BODY=fileContent)\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(model=MODEL, messages=messages, temperature=0.2)\n",
    "    return \"comments\", response.choices[0].message.content.strip()\n",
    "\n",
    "txtFolder2json(txtFolder=txtBeviljadeFolder, task_fn=getComments)\n",
    "txtFolder2json(txtFolder=txtAvslagFolder, task_fn=getComments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the top 10 descriptive categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCategories(comments_summary: json) -> str:\n",
    "    \"\"\"Finds the top 10 positive/negative descriptive categories from a json with lists of positive/negative comments.\n",
    "\n",
    "    Args:\n",
    "        comments_summary (json): json containing lists of positve/negative comments for each document.\n",
    "\n",
    "    Returns:\n",
    "        json: json with top 10 positive/negative category comments.\n",
    "    \"\"\"    \n",
    "\n",
    "    # Extract all positive and negative comments\n",
    "    comments_positive = []\n",
    "    comments_negative = []\n",
    "    for comments in comments_summary.values():\n",
    "        comments_positive += comments[\"positive\"]\n",
    "        comments_negative += comments[\"negative\"]\n",
    "\n",
    "    # Create messages for client\n",
    "    messages_positive = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"\"\"You are a script that outputs a valid python list of strings representing the top 10 descriptive categories.\n",
    "                The output must be a valid python list. Don't add explanation beyond the list.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "           \"role\": \"user\", \n",
    "           \"content\": f\"\"\"Identify the top 10 descriptive categories from the positive comments from the following text: {comments_positive}.\n",
    "                Output must include only a Python list with 10 descriptive category items of 3-5 words. Don't add explanation beyond the list. Don't make suggestions.\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    messages_negative = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"\"\"You are a script that outputs a valid python list of strings representing the top 10 descriptive categories.\n",
    "                The output must be a valid python list. Don't add explanation beyond the list.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "           \"role\": \"user\", \n",
    "           \"content\": f\"\"\"Identify the top 10 descriptive categories for the negative comments from the following text: {comments_negative}.\n",
    "                Output must include only a Python list with 10 descriptive category items of 3-5 words. Don't add explanation beyond the list. Don't make suggestions.\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    ## Positive categories\n",
    "    response_positive = client.chat.completions.create(model=MODEL, messages=messages_positive, temperature=0.4)\n",
    "    categories_positive = response_positive.choices[0].message.content.strip()\n",
    "    categories_positive = ast.literal_eval(categories_positive)\n",
    "    \n",
    "    ## Negative categories\n",
    "    response_negative = client.chat.completions.create(model=MODEL, messages=messages_negative, temperature=0.4)\n",
    "    categories_negative = response_negative.choices[0].message.content.strip()\n",
    "    categories_negative = ast.literal_eval(categories_negative)\n",
    "\n",
    "    ## Add to dictionary\n",
    "    categories = {'positive': categories_positive, 'negative': categories_negative}\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEVILJADE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outFolder + \"/beviljade_comments\" + \".json\", \"r\") as f:\n",
    "  beviljade_json = json.load(f)\n",
    "\n",
    "categories = findCategories(beviljade_json)\n",
    "beviljade_categories_pos = categories['positive']\n",
    "beviljade_categories_neg = categories['negative']\n",
    "\n",
    "print(\"Positive beviljade categories:\")\n",
    "for category in beviljade_categories_pos:\n",
    "    print(f\"- {category}\")\n",
    "print(\"\\nNegative beviljade categories:\")\n",
    "for category in beviljade_categories_neg:\n",
    "    print(f\"- {category}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVSLAG HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outFolder + \"/avslag_comments\" + \".json\", \"r\") as f:\n",
    "  avslag_json = json.load(f)\n",
    "\n",
    "categories = findCategories(avslag_json)\n",
    "avslag_categories_pos = categories['positive']\n",
    "avslag_categories_neg = categories['negative']\n",
    "\n",
    "print(\"Positive rejection categories:\")\n",
    "for category in avslag_categories_pos:\n",
    "  print(f\"- {category}\")\n",
    "  \n",
    "print(\"\\nNegative rejection categories:\")\n",
    "for category in avslag_categories_neg:\n",
    "  print(f\"- {category}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualize statistics based on extracted data**\n",
    "With the above json-files, visualize success rate for each category depending on grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both granted and denied data into pandas dataframes\n",
    "grantedData = pd.read_json(path_or_buf=os.path.join(outFolder, 'beviljade_grades.json'), orient=\"index\")\n",
    "deniedData = pd.read_json(path_or_buf=os.path.join(outFolder, 'avslag_grades.json'), orient=\"index\")\n",
    "column = grantedData.columns[-1]\n",
    "\n",
    "grantedData.loc[:,\"Result\"] = \"Granted\"\n",
    "deniedData.loc[:,\"Result\"] = \"Rejected\"\n",
    "\n",
    "df_grades = pd.concat([grantedData, deniedData])\n",
    "df_grades.loc[:,[column, \"Result\"]].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "granted_freq = {}\n",
    "for grade, group in df_grades.loc[:,[column, \"Result\"]].groupby(column):\n",
    "    granted_count = group[\"Result\"].value_counts(normalize=True).to_frame().reset_index()\n",
    "    if \"Granted\" in granted_count[\"Result\"].to_list():\n",
    "        granted_freq[int(grade)] = granted_count[granted_count[\"Result\"] == \"Granted\"][\"proportion\"].values[0]\n",
    "    else:\n",
    "        granted_freq[int(grade)] = 0\n",
    "print(granted_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_granted_freq = pd.DataFrame(granted_freq.items(), columns=[\"Grade\", \"Granted%\"])\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot bar and line plot.\n",
    "sns.lineplot(df_granted_freq, x=\"Grade\", y=\"Granted%\", ax=ax2, color=\"red\")\n",
    "ax1 = sns.histplot(df_grades, x=column, hue=\"Result\", ax=ax1, \n",
    "             discrete=True, multiple=\"layer\", shrink=0.3, edgecolor=None, legend=True)\n",
    "\n",
    "# label points on the plot\n",
    "for x, y in zip(df_granted_freq[\"Grade\"], df_granted_freq[\"Granted%\"]):\n",
    "    # the position of the data label relative to the data point can be adjusted by adding/subtracting a value from the x &/ y coordinates\n",
    "    plt.text(\n",
    "        x = x, # x-coordinate position of data label\n",
    "        y = y, # y-coordinate position of data label, adjusted to be 150 below the data point\n",
    "        s = f\"{y*100:.0f}%\" # data label, formatted to ignore decimals\n",
    "    )\n",
    "\n",
    "ax1.set_ylabel('Applications')\n",
    "ax2.set_ylabel('Success rate')\n",
    "ax2.set_ylim(0, 1.1)\n",
    "\n",
    "sns.move_legend(ax1, \"lower right\", bbox_to_anchor=(.5, 1), ncol=2, title=None, frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Output data to other formats**\n",
    "Create a dataframe and .xls for user-friendly purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both granted and denied\n",
    "grantedData = pd.read_json(path_or_buf=os.path.join(outFolder, 'beviljade_grades.json'), orient=\"index\")\n",
    "deniedData = pd.read_json(path_or_buf=os.path.join(outFolder, 'avslag_grades.json'), orient=\"index\")\n",
    "\n",
    "# Combine data with an additional 'Status' key\n",
    "grantedData.loc[:,\"Status\"] = \"Granted\"\n",
    "deniedData.loc[:,\"Status\"] = \"Rejected\"\n",
    "\n",
    "df_grades = pd.concat([grantedData, deniedData])\n",
    "df_grades.index.name = \"Document\"\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_grades)\n",
    "\n",
    "# Output excel-file\n",
    "df_grades.to_excel(os.path.join(outFolder,'output.xlsx'), index_label=\"Document\")\n",
    "df_grades.to_csv(os.path.join(outFolder,'grades.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
