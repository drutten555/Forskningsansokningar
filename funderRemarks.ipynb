{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Load packages and env, set up client, paths etc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os \n",
    "import fitz\n",
    "import ast\n",
    "import time\n",
    "from langchain.schema import Document\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "## Set up client\n",
    "client = OpenAI() # defaults to getting the key using os.environ.get(\"OPENAI_API_KEY\")\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "## Folder paths set here\n",
    "pdfFolder = os.getenv('PDF_AVSLAG_PATH')\n",
    "txtFolder = os.getenv('TXT_AVSLAG_PATH')\n",
    "\n",
    "# For plot outputs\n",
    "deniedPosPlotPath = os.getenv('DENIED_POS_PLOT')\n",
    "deniedNegPlotPath = os.getenv('DENIED_NEG_PLOT')\n",
    "\n",
    "commentsPath = os.getenv('JSON_AVSLAG_COMMENTS')\n",
    "catsPath = os.getenv('JSON_AVSLAG_CATS')\n",
    "imgPath = os.getenv('PLOT_PATH')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeText(filePath, content):\n",
    "    ## FUNCTION: Creates and writes to new .txt-file at filePath \n",
    "    ## INPUT: Path to write to, and which content to write to\n",
    "    ## OUTPUT: none\n",
    "    with open(filePath, 'w') as file:\n",
    "        file.write(content)\n",
    "    \n",
    "def cleanJSONresponse(jsonResponse):\n",
    "    ## FUNCTION: Turns an openai API-response to a usable json\n",
    "    ## INPUT: content part of Response from openAI API client\n",
    "    ## OUTPUT: content included between '{' and '}'\n",
    "    try:\n",
    "        # Attempt to find the first and last curly brace to extract valid JSON\n",
    "        start = jsonResponse.index('{')\n",
    "        end = jsonResponse.rindex('}') + 1\n",
    "        json_str = jsonResponse[start:end]\n",
    "        return json.loads(json_str)\n",
    "    except (ValueError, json.JSONDecodeError) as e:\n",
    "        print(f\"Failed to clean and parse JSON: {e}\")\n",
    "        return None\n",
    "\n",
    "def readText(filePath):\n",
    "    ## FUNCTION: Returns content from a .txt file at filePath\n",
    "    ## INPUT: Filepath\n",
    "    ## OUTPUT : Content of the .txt-file\n",
    "\n",
    "    with open(filePath, 'r') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "def loadOnePDF(filePath):\n",
    "    ## FUNCTION: Loads one pdf to document\n",
    "    ## INPUT: Path of pdf-file\n",
    "    ## OUTPUT : Document containing content of all pages in that pdf-file\n",
    "\n",
    "    text = \"\"\n",
    "    with fitz.open(filePath) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return Document(page_content=text, metadata={\"source\": filePath})\n",
    "\n",
    "def loadPDFs(folderPath):\n",
    "    ## FUNCTION: Loads all pdf-files to documents\n",
    "    ## INPUT: Path of folder containing pdf-files\n",
    "    ## OUTPUT : Document list containing content of all pages in all pdf-files\n",
    "    docs = []\n",
    "    for filename in os.listdir(folderPath):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            filePath = os.path.join(folderPath, filename)\n",
    "            docs.append(loadOnePDF(filePath))\n",
    "    return docs\n",
    "\n",
    "def PDFtoTXT(pdfFolder, txtFolder, verbose = False):\n",
    "    ## FUNCTION: Take folder of pdf's, fill an empty folder with .txt's - one for each pdf with it's content.\n",
    "    ## INPUT: the path to a folder of pdfs\n",
    "    ## OUTPUT: For each PDF in the input folder, returns a .txt with the content of the pdf\n",
    "\n",
    "    # Ensure the text folder exists\n",
    "    os.makedirs(txtFolder, exist_ok=True)\n",
    "    \n",
    "    documents = loadPDFs(pdfFolder)\n",
    "\n",
    "    for document in documents:\n",
    "        # Extract the filename without extension and append .txt\n",
    "        pdfFilename = os.path.basename(document.metadata['source'])\n",
    "        txtFilename = os.path.splitext(pdfFilename)[0] + '.txt'\n",
    "        txtPath = os.path.join(txtFolder, txtFilename)\n",
    "\n",
    "        # Write document content to a text file\n",
    "        writeText(txtPath, document.page_content)\n",
    "        if verbose:\n",
    "            print(f\"Converted {pdfFilename} to {txtFilename}\")\n",
    "\n",
    "\n",
    "def hasComments(filepath):\n",
    "    ## FUNCTION: Asks GPT to identify whether a txt document has comments or not, i.e. separates sifted from non-sifted documents.\n",
    "    ## INPUT: txtFile\n",
    "    ## OUTPUT: True or False\n",
    "\n",
    "    fileContent = readText(filepath)\n",
    "\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that determines whether comments are present for any of the graded categories in an application review.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"\"\"\n",
    "    Please check the following text and determine if there are comments for any of the categories that have been graded. Return \"True\" if there are comments for any or all of the categories. If there are no comments, return \"False\".\n",
    "    {fileContent}\n",
    "    \"\"\"}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content.strip().lower() == 'true'\n",
    "\n",
    "def getComments(filepath):\n",
    "    ## FUNCTION: Asks GPT to return a json with comments.\n",
    "    ## INPUT: path to txtFile\n",
    "    ## OUTPUT: json\n",
    "\n",
    "    fileContent = readText(filepath)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are method in a script. You extract and summarizes the essence of comments from research proposal reviews, identifying both positive and negative remarks. Your output is in JSON format with two keys: 'positive' and 'negative', each containing a list of short comments.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "        Extract and summarize the comments from the following text. Identify both positive and negative remarks and present them as two separate lists of short comments in JSON format with keys 'positive' and 'negative'.\n",
    "\n",
    "        {fileContent}\n",
    "        \"\"\"}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    # Print inside the function for debugging\n",
    "\n",
    "    # Extract the response text and ensure it's valid JSON\n",
    "    response_text = response.choices[0].message.content.strip()\n",
    "    response_json = cleanJSONresponse(response_text)\n",
    "    return response_json\n",
    "\n",
    "def extractJSON(response):\n",
    "    content = response.choices[0].message.content\n",
    "    \n",
    "    # Remove the backticks and json keyword from the content\n",
    "    if content.startswith('```json'):\n",
    "        content = content[7:]  # Remove the starting ```json\n",
    "    if content.endswith('```'):\n",
    "        content = content[:-3]  # Remove the ending ```\n",
    "\n",
    "    return content.strip()\n",
    "\n",
    "# for each file, input comments and receive true/false for that file based on predefined categories\n",
    "def categorizeComments(comments, positiveCat, negativeCat):\n",
    "    positiveCatStr = '\\n'.join([f\"{i+1}. {cat}\" for i, cat in enumerate(positiveCat)])\n",
    "    negativeCatStr = '\\n'.join([f\"{i+1}. {cat}\" for i, cat in enumerate(negativeCat)])\n",
    "\n",
    "    systemMsgContent = f\"\"\"You are a helpful assistant that summarizes the essence of comments from research proposal reviews and matches them to predefined categories. The categories are as follows:\n",
    "\n",
    "    Positive remarks:\n",
    "    {positiveCatStr}\n",
    "\n",
    "    Negative remarks:\n",
    "    {negativeCatStr}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": systemMsgContent},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "        Please summarize the comments from the following text. For each comment, identify which (if any) of the predefined categories it matches best - if it does not match any of the predefined categories, identify it as \"OTHER\". Return a JSON format of all categories, with a true or false value depending on if the category is present in the comments or not. Do not include repeats of categories. Categorize them under 'Positive remarks' and 'Negative remarks'.\n",
    "\n",
    "        {comments}\n",
    "        \"\"\"}\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    jsonContent = extractJSON(response)\n",
    "\n",
    "    return jsonContent\n",
    "\n",
    "# stores comments from all files\n",
    "def processDirectory(dirpath):\n",
    "    commentsDict = {}\n",
    "\n",
    "    for filename in os.listdir(dirpath):\n",
    "        if filename.endswith('.txt'): \n",
    "            filepath = os.path.join(dirpath, filename)\n",
    "            if hasComments(filepath):\n",
    "                comments = getComments(filepath)\n",
    "                commentsDict[filename] = comments\n",
    "\n",
    "    return commentsDict\n",
    "\n",
    "# identifies categories based on comments\n",
    "def findCategories(commentsSummary):\n",
    "    # Extract all positive and negative comments\n",
    "    commentsPositive = []\n",
    "    commentsNegative = []\n",
    "\n",
    "    for file, comments in commentsSummary.items():\n",
    "        commentsPositive.extend(comments.get('positive', []))\n",
    "        commentsNegative.extend(comments.get('negative', []))\n",
    "\n",
    "    # Create messages for OpenAI client\n",
    "    msgsPos = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a method in a script. Your input is a list of positive remarks as JSON. Your output should be a list (python) of 10 category names that best represent these remarks. Make sure that the categories include descriptive words. Don't just write ''Work plan'' but rather ''Clear work plan'' or ''well structured plan'' etc. Identify the 10 most frequent categories for the following positive remarks and return only the category names in the following format: ''category 1, category 2 ,...,category 9, category 10'' so that if inserted in between two brackets, it works as a list.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{commentsPositive}\"}\n",
    "    ]\n",
    "    \n",
    "    msgsNeg = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a method in a script. Your input is a list of negative remarks as JSON. Your output should be a list (python) of 10 category names that best represent these remarks. Make sure that the categories include descriptive words. Don't just write ''Work plan'' but rather ''Lacking work plan'' or ''poorly structured plan'' etc Identify the 10 most frequent categories for the following negative remarks and return only the category names in the following format: ''category 1, category 2 ,...,category 9, category 10'' so that if inserted in between two brackets, it works as a list.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{commentsNegative}\"}\n",
    "    ]\n",
    "\n",
    "    # Send requests to OpenAI\n",
    "    response_positive = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=msgsPos,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    response_negative = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=msgsNeg,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    catPos = response_positive.choices[0].message.content.strip()\n",
    "    catNeg = response_negative.choices[0].message.content.strip()\n",
    "\n",
    "    catPos = ast.literal_eval(catPos)\n",
    "    catNeg = ast.literal_eval(catNeg)\n",
    "\n",
    "    categories = {'positive': catPos, 'negative': catNeg}\n",
    "    \n",
    "    return categories\n",
    "\n",
    "def saveJSON(JSONpath, data):\n",
    "    # Write the updated dictionary to the JSON file\n",
    "    with open(JSONpath, 'w') as JSONfile:\n",
    "        json.dump(data, JSONfile, indent=4)\n",
    "\n",
    "    print(f\"JSON data has been written to {JSONpath}\")\n",
    "\n",
    "def loadExistingData(JSONpath):\n",
    "    # Load existing data from the JSON file if it exists\n",
    "    if os.path.exists(JSONpath):\n",
    "        with open(JSONpath, 'r') as JSONfile:\n",
    "            return json.load(JSONfile)\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "# takes json, returns dataframe\n",
    "def jsonDF(JSONpath):\n",
    "    with open(JSONpath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for file_name, remarks in data.items():\n",
    "        for remark_type, categories in remarks.items():\n",
    "            for category, value in categories.items():\n",
    "                records.append({\n",
    "                    'file_name': file_name,\n",
    "                    'remark_type': remark_type,\n",
    "                    'category': category,\n",
    "                    'value': value\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "def plotPosRemarks(df, posCat, savePath):\n",
    "    totalFiles = df['file_name'].nunique()\n",
    "    \n",
    "    summaryPos = df[(df['value'] == True) & (df['remark_type'] == 'Positive remarks') & (df['category'].isin(posCat))].groupby('category')['file_name'].nunique() / totalFiles * 100\n",
    "    summaryPos = summaryPos.sort_values(ascending=True)  # Sorting in ascending order\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    summaryPos.plot(kind='barh', color='skyblue')\n",
    "    plt.xlabel('Percentage of Files (%)')\n",
    "    plt.title('Summary of Positive Remarks')\n",
    "    plt.ylabel('Positive Categories')\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(savePath)  # Save the plot to the specified path\n",
    "    plt.close()  # Close the plot to free memory\n",
    "\n",
    "def plotNegRemarks(df, negCat, savePath):\n",
    "    totalFiles = df['file_name'].nunique()\n",
    "    \n",
    "    summaryNeg = df[(df['value'] == True) & (df['remark_type'] == 'Negative remarks') & (df['category'].isin(negCat))].groupby('category')['file_name'].nunique() / totalFiles * 100\n",
    "    summaryNeg = summaryNeg.sort_values(ascending=True)  # Sorting in ascending order\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    summaryNeg.plot(kind='barh', color='salmon')\n",
    "    plt.xlabel('Percentage of Files (%)')\n",
    "    plt.title('Summary of Negative Remarks')\n",
    "    plt.ylabel('Negative Categories')\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(savePath)  # Save the plot to the specified path\n",
    "    plt.close()  # Close the plot to free memory\n",
    "\n",
    "# Function to calculate time difference in a readable format\n",
    "def formatTimeDifference(start, end):\n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(end - start))\n",
    "\n",
    "# Function to print progress\n",
    "def printProgress(current, total, startTime):\n",
    "    elapsedTime = time.time() - startTime\n",
    "    remainingTime = (elapsedTime / current) * (total - current) if current > 0 else 0\n",
    "    print(f\"Processed {current}/{total} files. Estimated time remaining: {formatTimeDifference(0, remainingTime)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Main** \n",
    "Might take some time to run, has varied from 6 to 30 min. One run resulted in:\n",
    "\n",
    "Durations:\n",
    "1. Converting PDFs to TXTs: 00:00:00\n",
    "2. Finding and summarizing comments: 00:04:12\n",
    "3. Finding categories: 00:00:05\n",
    "4. Categorizing comments: 00:03:28\n",
    "Total time taken: 00:07:46\n",
    "Total documents processed: 28\n",
    "\n",
    "Percentage of total time each step took:\n",
    "1. Converting PDFs to TXTs: 0.07%\n",
    "2. Finding and summarizing comments: 54.06%\n",
    "3. Finding categories: 1.12%\n",
    "4. Categorizing comments: 44.75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time management\n",
    "startTime = time.time()\n",
    "pdfToTxtStart = startTime\n",
    "\n",
    "# Take TXT-dir and make PDF-dir\n",
    "PDFtoTXT(pdfFolder, txtFolder, verbose=False)\n",
    "print('PDFtoTXT done')\n",
    "\n",
    "## Time management\n",
    "pdfToTxtEnd = time.time()\n",
    "commentsSummaryStart = pdfToTxtEnd\n",
    "\n",
    "# Get categories\n",
    "commentsSummary = processDirectory(txtFolder)\n",
    "with open(commentsPath, 'w') as outfile:\n",
    "    json.dump(commentsSummary, outfile, indent=4)\n",
    "print('Comments have been summarized and saved')\n",
    "\n",
    "## Time management\n",
    "commentsSummaryEnd = time.time()\n",
    "categoriesStart = commentsSummaryEnd\n",
    "\n",
    "categories = findCategories(commentsSummary)\n",
    "print('Categories have been identified')\n",
    "\n",
    "## Time management\n",
    "categoriesEnd = time.time()\n",
    "\n",
    "# Load existing data once\n",
    "existingData = loadExistingData(catsPath)\n",
    "\n",
    "# Update the existing data with new categorized comments\n",
    "totalFiles = len(commentsSummary)\n",
    "categorizationStart = categoriesEnd\n",
    "\n",
    "for i, (fileName, comments) in enumerate(commentsSummary.items(), 1):\n",
    "    printProgress(i, totalFiles, categorizationStart)\n",
    "    categorizedComments = categorizeComments(comments, categories['positive'], categories['negative'])\n",
    "    existingData[fileName] = json.loads(categorizedComments)  # assuming categorizedComments is a JSON string\n",
    "\n",
    "## Time management\n",
    "categorizationEnd = time.time()\n",
    "\n",
    "# Save the updated data to the JSON file once\n",
    "saveJSON(catsPath, existingData)\n",
    "\n",
    "## Time management and prints ################################################################################################################################\n",
    "########################################################################################################################################################\n",
    "pdfToTxtDuration = pdfToTxtEnd - pdfToTxtStart\n",
    "commentsSummaryDuration = commentsSummaryEnd - commentsSummaryStart\n",
    "categoriesDuration = categoriesEnd - categoriesStart\n",
    "categorizationDuration = categorizationEnd - categorizationStart\n",
    "totalDuration = categorizationEnd - startTime\n",
    "\n",
    "# Print the durations\n",
    "print(f\"\\nDurations:\")\n",
    "print(f\"1. Converting PDFs to TXTs: {formatTimeDifference(0, pdfToTxtDuration)}\")\n",
    "print(f\"2. Finding and summarizing comments: {formatTimeDifference(0, commentsSummaryDuration)}\")\n",
    "print(f\"3. Finding categories: {formatTimeDifference(0, categoriesDuration)}\")\n",
    "print(f\"4. Categorizing comments: {formatTimeDifference(0, categorizationDuration)}\")\n",
    "print(f\"Total time taken: {formatTimeDifference(0, totalDuration)}\")\n",
    "print(f\"Total documents processed: {totalFiles}\")\n",
    "\n",
    "# Calculate and print the percentage of time each step took\n",
    "totalPercentage = totalDuration / 100\n",
    "print(\"\\nPercentage of total time each step took:\")\n",
    "print(f\"1. Converting PDFs to TXTs: {pdfToTxtDuration / totalPercentage:.2f}%\")\n",
    "print(f\"2. Finding and summarizing comments: {commentsSummaryDuration / totalPercentage:.2f}%\")\n",
    "print(f\"3. Finding categories: {categoriesDuration / totalPercentage:.2f}%\")\n",
    "print(f\"4. Categorizing comments: {categorizationDuration / totalPercentage:.2f}%\")\n",
    "\n",
    "df = jsonDF(catsPath)\n",
    "\n",
    "plotPosRemarks(df, categories['positive'],deniedPosPlotPath)\n",
    "plotNegRemarks(df, categories['negative'],deniedNegPlotPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
